{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12361827,"sourceType":"datasetVersion","datasetId":7779864}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import optuna\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, datasets\nimport torchvision\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt \nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport os\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T14:15:33.431312Z","iopub.execute_input":"2025-07-03T14:15:33.431619Z","iopub.status.idle":"2025-07-03T14:15:42.841751Z","shell.execute_reply.started":"2025-07-03T14:15:33.431595Z","shell.execute_reply":"2025-07-03T14:15:42.841012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mean = [0.5, 0.5, 0.5]\nstd = [0.5, 0.5, 0.5]\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((150, 150)),            \n    transforms.RandomHorizontalFlip(),        \n    transforms.RandomRotation(15),\n    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std)\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((150, 150)),            \n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std)\n])\n\nbatch_size = 16\n\ndata_dir = \"/kaggle/input/teeth-dataset/Teeth_Dataset/\"\ntrain_dataset = datasets.ImageFolder(os.path.join(data_dir, \"Training\"), transform=train_transform)\nval_dataset = datasets.ImageFolder(os.path.join(data_dir, \"Validation\"), transform=test_transform)\ntest_dataset = datasets.ImageFolder(os.path.join(data_dir, \"Testing\"), transform=test_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\nnum_classes = len(train_dataset.classes)\n\n\n ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T14:15:42.843147Z","iopub.execute_input":"2025-07-03T14:15:42.843663Z","iopub.status.idle":"2025-07-03T14:15:56.299787Z","shell.execute_reply.started":"2025-07-03T14:15:42.843613Z","shell.execute_reply":"2025-07-03T14:15:56.299113Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def inverse_normalize(img_tensor, mean=[0.5]*3, std=[0.5]*3):\n    inv = transforms.Normalize(\n        mean=[-m/s for m, s in zip(mean, std)],\n        std=[1/s for s in std]\n    )\n    return inv(img_tensor)\n\n\ndef visualize_augmented_vs_original(train_dataset, test_transform, n_images=6):\n    raw_dataset = datasets.ImageFolder(train_dataset.root, transform=test_transform)\n    raw_loader = DataLoader(raw_dataset, batch_size=n_images, shuffle=True)\n    aug_loader = DataLoader(train_dataset, batch_size=n_images, shuffle=True)\n\n    raw_imgs, _ = next(iter(raw_loader))\n    aug_imgs, _ = next(iter(aug_loader))\n\n    raw_imgs = torch.stack([inverse_normalize(img) for img in raw_imgs])\n    aug_imgs = torch.stack([inverse_normalize(img) for img in aug_imgs])\n\n    def show_grid(images, title):\n        grid = torchvision.utils.make_grid(images, nrow=n_images)\n        npimg = grid.numpy().transpose((1, 2, 0))\n        plt.figure(figsize=(12, 3))\n        plt.imshow(np.clip(npimg, 0, 1))\n        plt.axis('off')\n        plt.title(title)\n        plt.show()\n\n    show_grid(raw_imgs, \"Original Images\")\n    show_grid(aug_imgs, \"Augmented Images\")\n\ndef plot_class_distribution(train_dataset):\n    class_names = train_dataset.classes\n    class_counts = [0] * len(class_names)\n    for _, label in train_dataset.samples:\n        class_counts[label] += 1\n\n    df = pd.DataFrame({\n        \"Class\": class_names,\n        \"Count\": class_counts\n    })\n\n    plt.figure(figsize=(8, 4))\n    sns.barplot(data=df, x=\"Class\", y=\"Count\")\n    plt.title(\"Training Set Class Distribution\")\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T14:15:56.300566Z","iopub.execute_input":"2025-07-03T14:15:56.300785Z","iopub.status.idle":"2025-07-03T14:15:56.310079Z","shell.execute_reply.started":"2025-07-03T14:15:56.300768Z","shell.execute_reply":"2025-07-03T14:15:56.309131Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualize_augmented_vs_original(train_dataset, test_transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T14:15:56.311784Z","iopub.execute_input":"2025-07-03T14:15:56.312096Z","iopub.status.idle":"2025-07-03T14:15:58.718456Z","shell.execute_reply.started":"2025-07-03T14:15:56.312078Z","shell.execute_reply":"2025-07-03T14:15:58.717423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_class_distribution(train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T14:15:58.719473Z","iopub.execute_input":"2025-07-03T14:15:58.719784Z","iopub.status.idle":"2025-07-03T14:15:58.935746Z","shell.execute_reply.started":"2025-07-03T14:15:58.719760Z","shell.execute_reply":"2025-07-03T14:15:58.934600Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self, num_classes, dropout=0.5):\n        super(CNN, self).__init__()\n\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n\n        with torch.no_grad():\n            dummy = torch.zeros(1, 3, 150, 150) \n            x = self.pool(F.relu(self.conv1(dummy)))\n            x = self.pool(F.relu(self.conv2(x)))\n            x = self.pool(F.relu(self.conv3(x)))\n            self.flattened_size = x.view(1, -1).shape[1]\n\n        self.fc1 = nn.Linear(self.flattened_size, 512)\n        self.dropout = nn.Dropout(dropout)\n        self.fc2 = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        return self.fc2(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T14:15:58.936561Z","iopub.execute_input":"2025-07-03T14:15:58.936808Z","iopub.status.idle":"2025-07-03T14:15:58.944524Z","shell.execute_reply.started":"2025-07-03T14:15:58.936789Z","shell.execute_reply":"2025-07-03T14:15:58.943846Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = CNN(num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001)\n\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    train_acc = correct / total\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}, Accuracy: {train_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T14:56:17.744865Z","iopub.execute_input":"2025-07-03T14:56:17.745555Z","iopub.status.idle":"2025-07-03T15:23:10.699395Z","shell.execute_reply.started":"2025-07-03T14:56:17.745533Z","shell.execute_reply":"2025-07-03T15:23:10.698678Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nval_acc = correct / total\nprint(f\"Validation Accuracy: {val_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T15:25:26.762471Z","iopub.execute_input":"2025-07-03T15:25:26.763106Z","iopub.status.idle":"2025-07-03T15:25:30.686572Z","shell.execute_reply.started":"2025-07-03T15:25:26.763082Z","shell.execute_reply":"2025-07-03T15:25:30.685696Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\ntest_acc = correct / total\nprint(f\"test Accuracy: {test_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T15:25:33.520204Z","iopub.execute_input":"2025-07-03T15:25:33.520833Z","iopub.status.idle":"2025-07-03T15:25:37.423662Z","shell.execute_reply.started":"2025-07-03T15:25:33.520812Z","shell.execute_reply":"2025-07-03T15:25:37.422551Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}